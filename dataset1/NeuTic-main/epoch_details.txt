(py10) E:\code\dataset1\NeuTic-main>python train.py
============================================================
项目名称：云平台上的加密 TLS 流量分类（6类别）
姓名：黄宇琳
当前系统时间：2025-12-06 23:49:57
============================================================
开始 NeuTic 模型训练与验证（6类别）
使用设备: cpu
============================================================
============================================================
【数据集类别分布与权重计算】
  dy (ID:0): 1246 个样本, 权重: 0.9834
  elm (ID:1): 1129 个样本, 权重: 1.0853
  tpp (ID:2): 1206 个样本, 权重: 1.0160
  tt (ID:3): 1176 个样本, 权重: 1.0419
  xg (ID:4): 1302 个样本, 权重: 0.9411
  yk (ID:5): 1314 个样本, 权重: 0.9325
============================================================
数据加载完成，总共 7373 个样本。
划分结果: 训练集 5161, 验证集 1105, 测试集 1107
标签映射: {np.str_('dy'): 0, np.str_('elm'): 1, np.str_('tpp'): 2, np.str_('tt'): 3, np.str_('xg'): 4, np.str_('yk'): 5}

模型总参数量: 52,093,446
分类类别数: 6
使用带权重的交叉熵损失函数处理类别不平衡
============================================================

开始训练...

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.6679    0.9427    0.7819       192
         elm     0.8895    0.8895    0.8895       172
         tpp     0.7419    0.7372    0.7395       156
          tt     0.5571    0.8619    0.6768       181
          xg     0.8163    0.4188    0.5536       191
          yk     0.8760    0.5305    0.6608       213

    accuracy                         0.7222      1105
   macro avg     0.7581    0.7301    0.7170      1105
weighted avg     0.7605    0.7222    0.7127      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [01/30] | Train Loss: 1.2224, Train Acc: 56.56% | Val Loss: 0.6658, Val Acc: 72.22%
   -> 保存新的最佳模型，验证准确率: 72.22%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8993    0.6979    0.7859       192
         elm     0.8342    0.9360    0.8822       172
         tpp     0.5965    0.8718    0.7083       156
          tt     0.6180    0.6077    0.6128       181
          xg     0.7597    0.6126    0.6783       191
          yk     0.7734    0.7371    0.7548       213

    accuracy                         0.7376      1105
   macro avg     0.7469    0.7439    0.7371      1105
weighted avg     0.7519    0.7376    0.7370      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [02/30] | Train Loss: 0.6653, Train Acc: 72.43% | Val Loss: 0.5936, Val Acc: 73.76%
   -> 保存新的最佳模型，验证准确率: 73.76%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.7867    0.9219    0.8489       192
         elm     0.8889    0.9302    0.9091       172
         tpp     0.8333    0.8013    0.8170       156
          tt     0.6408    0.5028    0.5635       181
          xg     0.6164    0.7487    0.6761       191
          yk     0.8977    0.7418    0.8123       213

    accuracy                         0.7729      1105
   macro avg     0.7773    0.7744    0.7712      1105
weighted avg     0.7773    0.7729    0.7701      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [03/30] | Train Loss: 0.5769, Train Acc: 76.40% | Val Loss: 0.5577, Val Acc: 77.29%
   -> 保存新的最佳模型，验证准确率: 77.29%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8295    0.9375    0.8802       192
         elm     0.9448    0.8953    0.9194       172
         tpp     0.8483    0.7885    0.8173       156
          tt     0.6171    0.9171    0.7378       181
          xg     0.8624    0.4921    0.6267       191
          yk     0.8366    0.7934    0.8145       213

    accuracy                         0.8018      1105
   macro avg     0.8231    0.8040    0.7993      1105
weighted avg     0.8224    0.8018    0.7976      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [04/30] | Train Loss: 0.4902, Train Acc: 79.15% | Val Loss: 0.5075, Val Acc: 80.18%
   -> 保存新的最佳模型，验证准确率: 80.18%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8009    0.9010    0.8480       192
         elm     0.9075    0.9128    0.9101       172
         tpp     0.7574    0.8205    0.7877       156
          tt     0.6411    0.8785    0.7413       181
          xg     0.8919    0.5183    0.6556       191
          yk     0.8511    0.7512    0.7980       213

    accuracy                         0.7928      1105
   macro avg     0.8083    0.7970    0.7901      1105
weighted avg     0.8106    0.7928    0.7888      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [05/30] | Train Loss: 0.4480, Train Acc: 81.52% | Val Loss: 0.6293, Val Acc: 79.28%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.7660    0.9375    0.8431       192
         elm     0.9266    0.9535    0.9398       172
         tpp     0.9576    0.7244    0.8248       156
          tt     0.6436    0.3591    0.4610       181
          xg     0.6016    0.8063    0.6890       191
          yk     0.7982    0.8169    0.8074       213

    accuracy                         0.7692      1105
   macro avg     0.7822    0.7663    0.7609      1105
weighted avg     0.7758    0.7692    0.7595      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [06/30] | Train Loss: 0.4062, Train Acc: 83.34% | Val Loss: 0.6442, Val Acc: 76.92%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8550    0.8906    0.8724       192
         elm     0.9408    0.9244    0.9326       172
         tpp     0.7963    0.8269    0.8113       156
          tt     0.6882    0.3536    0.4672       181
          xg     0.5789    0.8639    0.6933       191
          yk     0.8571    0.7887    0.8215       213

    accuracy                         0.7747      1105
   macro avg     0.7861    0.7747    0.7664      1105
weighted avg     0.7854    0.7747    0.7660      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [07/30] | Train Loss: 0.3530, Train Acc: 84.81% | Val Loss: 0.5524, Val Acc: 77.47%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.9040    0.8333    0.8672       192
         elm     0.9739    0.8663    0.9169       172
         tpp     0.7636    0.8077    0.7850       156
          tt     0.6145    0.8453    0.7116       181
          xg     0.8430    0.5340    0.6538       191
          yk     0.7375    0.8310    0.7815       213

    accuracy                         0.7846      1105
   macro avg     0.8061    0.7863    0.7860      1105
weighted avg     0.8050    0.7846    0.7845      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [08/30] | Train Loss: 0.2958, Train Acc: 87.81% | Val Loss: 0.6157, Val Acc: 78.46%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8086    0.8802    0.8429       192
         elm     0.9451    0.9012    0.9226       172
         tpp     0.8667    0.7500    0.8041       156
          tt     0.6226    0.9116    0.7399       181
          xg     0.8952    0.4921    0.6351       191
          yk     0.7974    0.8498    0.8227       213

    accuracy                         0.7973      1105
   macro avg     0.8226    0.7975    0.7946      1105
weighted avg     0.8204    0.7973    0.7932      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [09/30] | Train Loss: 0.2856, Train Acc: 88.06% | Val Loss: 0.5374, Val Acc: 79.73%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8510    0.9219    0.8850       192
         elm     0.9627    0.9012    0.9309       172
         tpp     0.7360    0.8397    0.7844       156
          tt     0.7044    0.6188    0.6588       181
          xg     0.6820    0.7749    0.7255       191
          yk     0.8901    0.7606    0.8203       213

    accuracy                         0.8009      1105
   macro avg     0.8044    0.8028    0.8008      1105
weighted avg     0.8065    0.8009    0.8009      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [10/30] | Train Loss: 0.2569, Train Acc: 89.27% | Val Loss: 0.6924, Val Acc: 80.09%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8593    0.8906    0.8747       192
         elm     0.9632    0.9128    0.9373       172
         tpp     0.7401    0.8397    0.7868       156
          tt     0.7107    0.6243    0.6647       181
          xg     0.6854    0.7644    0.7228       191
          yk     0.8557    0.7793    0.8157       213

    accuracy                         0.8000      1105
   macro avg     0.8024    0.8019    0.8003      1105
weighted avg     0.8036    0.8000    0.8000      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [11/30] | Train Loss: 0.2662, Train Acc: 88.98% | Val Loss: 0.6394, Val Acc: 80.00%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8902    0.8021    0.8438       192
         elm     0.9415    0.9360    0.9388       172
         tpp     0.7683    0.8077    0.7875       156
          tt     0.6622    0.8122    0.7295       181
          xg     0.7821    0.6387    0.7032       191
          yk     0.8128    0.8357    0.8241       213

    accuracy                         0.8036      1105
   macro avg     0.8095    0.8054    0.8045      1105
weighted avg     0.8100    0.8036    0.8038      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [12/30] | Train Loss: 0.2432, Train Acc: 89.85% | Val Loss: 0.6323, Val Acc: 80.36%
   -> 保存新的最佳模型，验证准确率: 80.36%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8190    0.9427    0.8765       192
         elm     0.9722    0.8140    0.8861       172
         tpp     0.8000    0.7949    0.7974       156
          tt     0.7095    0.5801    0.6383       181
          xg     0.6567    0.8010    0.7217       191
          yk     0.8186    0.7840    0.8010       213

    accuracy                         0.7873      1105
   macro avg     0.7960    0.7861    0.7868      1105
weighted avg     0.7941    0.7873    0.7865      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [13/30] | Train Loss: 0.2237, Train Acc: 91.20% | Val Loss: 0.8474, Val Acc: 78.73%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8647    0.9323    0.8972       192
         elm     0.9390    0.8953    0.9167       172
         tpp     0.8311    0.7885    0.8092       156
          tt     0.6837    0.7403    0.7109       181
          xg     0.7586    0.6911    0.7233       191
          yk     0.8333    0.8451    0.8392       213

    accuracy                         0.8163      1105
   macro avg     0.8184    0.8154    0.8161      1105
weighted avg     0.8175    0.8163    0.8160      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [14/30] | Train Loss: 0.1954, Train Acc: 92.09% | Val Loss: 0.6439, Val Acc: 81.63%
   -> 保存新的最佳模型，验证准确率: 81.63%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8711    0.8802    0.8756       192
         elm     0.9518    0.9186    0.9349       172
         tpp     0.7074    0.8526    0.7733       156
          tt     0.6981    0.8177    0.7532       181
          xg     0.7746    0.7016    0.7363       191
          yk     0.9128    0.7371    0.8156       213

    accuracy                         0.8136      1105
   macro avg     0.8193    0.8180    0.8148      1105
weighted avg     0.8236    0.8136    0.8147      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [15/30] | Train Loss: 0.1987, Train Acc: 91.86% | Val Loss: 0.7706, Val Acc: 81.36%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.7787    0.9531    0.8571       192
         elm     0.9548    0.8605    0.9052       172
         tpp     0.8310    0.7564    0.7919       156
          tt     0.6145    0.8895    0.7269       181
          xg     0.8750    0.5131    0.6469       191
          yk     0.8392    0.7840    0.8107       213

    accuracy                         0.7919      1105
   macro avg     0.8155    0.7928    0.7898      1105
weighted avg     0.8149    0.7919    0.7888      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [16/30] | Train Loss: 0.2013, Train Acc: 92.25% | Val Loss: 0.8979, Val Acc: 79.19%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8670    0.9167    0.8911       192
         elm     0.9405    0.9186    0.9294       172
         tpp     0.8333    0.7692    0.8000       156
          tt     0.6727    0.8177    0.7382       181
          xg     0.7922    0.6387    0.7072       191
          yk     0.8380    0.8498    0.8438       213

    accuracy                         0.8190      1105
   macro avg     0.8240    0.8184    0.8183      1105
weighted avg     0.8233    0.8190    0.8183      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [17/30] | Train Loss: 0.1905, Train Acc: 92.77% | Val Loss: 0.7366, Val Acc: 81.90%  
   -> 保存新的最佳模型，验证准确率: 81.90%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.7802    0.9427    0.8538       192
         elm     0.8865    0.9535    0.9188       172
         tpp     0.7341    0.8141    0.7720       156
          tt     0.7176    0.5193    0.6026       181
          xg     0.6549    0.7749    0.7098       191
          yk     0.9177    0.6808    0.7817       213

    accuracy                         0.7774      1105
   macro avg     0.7818    0.7809    0.7731      1105
weighted avg     0.7848    0.7774    0.7724      1105
, Val Acc: 77.74%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.9576    0.8229    0.8852       192
         elm     0.8939    0.9302    0.9117       172
         tpp     0.8052    0.7949    0.8000       156
          tt     0.7103    0.5691    0.6319       181
          xg     0.6930    0.7801    0.7340       191
          yk     0.7733    0.8967    0.8304       213

    accuracy                         0.8009      1105
   macro avg     0.8055    0.7990    0.7989      1105
weighted avg     0.8044    0.8009    0.7991      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [19/30] | Train Loss: 0.1574, Train Acc: 93.70% | Val Loss: 0.7158, Val Acc: 80.09%     

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8872    0.9010    0.8941       192
         elm     0.9341    0.9070    0.9204       172
         tpp     0.8013    0.8013    0.8013       156
          tt     0.6432    0.8564    0.7346       181
          xg     0.8000    0.5864    0.6767       191
          yk     0.8447    0.8169    0.8305       213

    accuracy                         0.8100      1105
   macro avg     0.8184    0.8115    0.8096      1105
weighted avg     0.8191    0.8100    0.8091      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     











Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     










Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     









Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     







Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     





Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     




Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     



Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     


Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     

Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     


Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     
Epoch [20/30] | Train Loss: 0.1578, Train Acc: 93.95% | Val Loss: 0.7064, Val Acc: 81.00%     

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8208    0.9062    0.8614       192
         elm     0.9434    0.8721    0.9063       172
         tpp     0.8529    0.7436    0.7945       156
          tt     0.7310    0.6906    0.7102       181
          xg     0.6774    0.7696    0.7206       191
          yk     0.8143    0.8028    0.8085       213

    accuracy                         0.7991      1105
   macro avg     0.8066    0.7975    0.8003      1105
weighted avg     0.8037    0.7991    0.7997      1105

E:\code\dataset1\NeuTic-main\train.py:158: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(8, 6))  # 增大图形尺寸以适应6个类别
混淆矩阵已保存为 'confusion_matrix.png'
Epoch [21/30] | Train Loss: 0.1551, Train Acc: 94.21% | Val Loss: 0.8909, Val Acc: 79.91%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.9560    0.7917    0.8661       192
         elm     0.9138    0.9244    0.9191       172
         tpp     0.8013    0.8013    0.8013       156
          tt     0.6727    0.8177    0.7382       181
          xg     0.8065    0.6545    0.7225       191
          yk     0.7759    0.8779    0.8238       213

    accuracy                         0.8109      1105
   macro avg     0.8210    0.8112    0.8118      1105
weighted avg     0.8206    0.8109    0.8113      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [22/30] | Train Loss: 0.1383, Train Acc: 95.16% | Val Loss: 0.8281, Val Acc: 81.09%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8488    0.9062    0.8766       192
         elm     0.9390    0.8953    0.9167       172
         tpp     0.9487    0.7115    0.8132       156
          tt     0.7019    0.6243    0.6608       181
          xg     0.6754    0.8063    0.7351       191
          yk     0.8000    0.8638    0.8307       213

    accuracy                         0.8054      1105
   macro avg     0.8190    0.8013    0.8055      1105
weighted avg     0.8135    0.8054    0.8052      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [23/30] | Train Loss: 0.1267, Train Acc: 95.62% | Val Loss: 0.8032, Val Acc: 80.54%     

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8711    0.8802    0.8756       192
         elm     0.9506    0.8953    0.9222       172
         tpp     0.8288    0.7756    0.8013       156
          tt     0.7286    0.5635    0.6355       181
          xg     0.6513    0.8115    0.7226       191
          yk     0.7911    0.8357    0.8128       213

    accuracy                         0.7955      1105
   macro avg     0.8036    0.7937    0.7950      1105
weighted avg     0.8007    0.7955    0.7945      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [24/30] | Train Loss: 0.1214, Train Acc: 95.35% | Val Loss: 0.8965, Val Acc: 79.55%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8524    0.9323    0.8905       192
         elm     0.9244    0.9244    0.9244       172
         tpp     0.7607    0.7949    0.7774       156
          tt     0.7039    0.6961    0.7000       181
          xg     0.7249    0.7173    0.7211       191
          yk     0.8542    0.7700    0.8099       213

    accuracy                         0.8045      1105
   macro avg     0.8034    0.8058    0.8039      1105
weighted avg     0.8046    0.8045    0.8038      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [25/30] | Train Loss: 0.1202, Train Acc: 95.87% | Val Loss: 0.8468, Val Acc: 80.45%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8454    0.9115    0.8772       192
         elm     0.9789    0.8081    0.8854       172
         tpp     0.7456    0.8077    0.7754       156
          tt     0.6364    0.8122    0.7136       181
          xg     0.7545    0.6597    0.7039       191
          yk     0.8519    0.7559    0.8010       213

    accuracy                         0.7910      1105
   macro avg     0.8021    0.7925    0.7927      1105
weighted avg     0.8034    0.7910    0.7927      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [26/30] | Train Loss: 0.1208, Train Acc: 95.31% | Val Loss: 1.1912, Val Acc: 79.10%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.7930    0.9375    0.8592       192
         elm     0.9467    0.9302    0.9384       172
         tpp     0.8392    0.7692    0.8027       156
          tt     0.6800    0.7514    0.7139       181
          xg     0.7740    0.7173    0.7446       191
          yk     0.8836    0.7840    0.8308       213

    accuracy                         0.8145      1105
   macro avg     0.8194    0.8149    0.8149      1105
weighted avg     0.8191    0.8145    0.8145      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [27/30] | Train Loss: 0.1677, Train Acc: 94.42% | Val Loss: 0.8314, Val Acc: 81.45%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8544    0.9167    0.8844       192
         elm     0.9186    0.9186    0.9186       172
         tpp     0.8623    0.7628    0.8095       156
          tt     0.7045    0.6851    0.6947       181
          xg     0.7459    0.7225    0.7340       191
          yk     0.7807    0.8357    0.8073       213

    accuracy                         0.8081      1105
   macro avg     0.8111    0.8069    0.8081      1105
weighted avg     0.8080    0.8081    0.8072      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [28/30] | Train Loss: 0.1076, Train Acc: 96.09% | Val Loss: 0.8755, Val Acc: 80.81%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8063    0.9323    0.8647       192
         elm     0.9750    0.9070    0.9398       172
         tpp     0.7987    0.7885    0.7935       156
          tt     0.6815    0.5912    0.6331       181
          xg     0.6419    0.7696    0.7000       191
          yk     0.8689    0.7465    0.8030       213

    accuracy                         0.7882      1105
   macro avg     0.7954    0.7892    0.7890      1105
weighted avg     0.7947    0.7882    0.7881      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [29/30] | Train Loss: 0.1239, Train Acc: 95.52% | Val Loss: 1.0249, Val Acc: 78.82%

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.9130    0.8750    0.8936       192
         elm     0.8919    0.9593    0.9244       172
         tpp     0.7345    0.8333    0.7808       156
          tt     0.7467    0.6188    0.6767       181
          xg     0.7198    0.7801    0.7487       191
          yk     0.8614    0.8169    0.8386       213

    accuracy                         0.8127      1105
   macro avg     0.8112    0.8139    0.8105      1105
weighted avg     0.8139    0.8127    0.8113      1105

混淆矩阵已保存为 'confusion_matrix.png'
Epoch [30/30] | Train Loss: 0.1040, Train Acc: 96.20% | Val Loss: 0.7963, Val Acc: 81.27%

============================================================
在测试集上进行最终评估...

============================================================
详细分类报告:
              precision    recall  f1-score   support

          dy     0.8960    0.8757    0.8857       177
         elm     0.9244    0.8833    0.9034       180
         tpp     0.8757    0.8222    0.8481       180
          tt     0.6634    0.8024    0.7263       167
          xg     0.8167    0.6901    0.7481       213
          yk     0.8104    0.9000    0.8529       190

    accuracy                         0.8257      1107
   macro avg     0.8311    0.8290    0.8274      1107
weighted avg     0.8323    0.8257    0.8263      1107

混淆矩阵已保存为 'confusion_matrix.png'

测试集结果 -> 损失: 0.7848, 准确率: 82.57%

============================================================
【6类别分类任务评估】
基础学习能力：测试准确率应显著高于随机猜测 (16.67%)。
你的结果: 82.57% ✅

【各类别详细性能】
  dy: 精确率=0.896, 召回率=0.876, F1=0.886
  elm: 精确率=0.924, 召回率=0.883, F1=0.903
  tpp: 精确率=0.876, 召回率=0.822, F1=0.848
  tt: 精确率=0.663, 召回率=0.802, F1=0.726
  xg: 精确率=0.817, 召回率=0.690, F1=0.748
  yk: 精确率=0.810, 召回率=0.900, F1=0.853

所有结果已保存至 test_results.npy